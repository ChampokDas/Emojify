# -*- coding: utf-8 -*-
"""c435modelling.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/138S53g6_cjJ-IqB_rXoe7IXm_F5JfaQA
"""

pip install tensorflow-gpu

from __future__ import absolute_import, division, print_function, unicode_literals
import matplotlib.pylab as plt
import tensorflow as tf
import tensorflow_hub as hub
import numpy as np
import pandas as pd
print(tf.__version__)

pd.set_option("display.precision", 8)

print("Version: ", tf.__version__)
print("Hub version: ", hub.__version__)
print("Eager mode: ", tf.executing_eagerly())
print("GPU is", "available" if tf.test.is_gpu_available() else "NOT AVAILABLE")

"""Connecting Dataset"""

from google.colab import drive
drive.mount('/content/drive')

data_root = '/content/drive/My Drive/Colab Notebooks/TRAINING_IMAGES';

IMAGE_SHAPE = (224,224)
TRAINING_DIR = str(data_root)
datagen_kwargs = dict(rescale=1./255, validation_split=.20)
valid_datagen=tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs)
valid_generator = valid_datagen.flow_from_directory(
    TRAINING_DIR,
    subset="validation",
    shuffle=True,
    target_size=IMAGE_SHAPE
)

train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs)
train_generator = train_datagen.flow_from_directory(
    TRAINING_DIR,
    subset="training",
    shuffle=True,
    target_size=IMAGE_SHAPE
)

image_batch_train, label_batch_train = next(iter(train_generator))
dataset_labels = sorted(train_generator.class_indices.items(), key=lambda pair:pair[1])
dataset_labels = np.array([key.title() for key, value in dataset_labels])

"""Training"""

model = tf.keras.Sequential([
                             hub.KerasLayer("https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4",
                             output_shape=[1280],
                             trainable=False),
                             tf.keras.layers.Dropout(0.4),
                             tf.keras.layers.Dense(train_generator.num_classes, activation='softmax')
])
model.build([None, 224, 224, 3])
model.summary()

print('Compiling...')
model.compile(
    optimizer=tf.keras.optimizers.Adam(),
    loss='categorical_crossentropy',
    metrics=['acc'])
print('COMPILED!')

"""Training here!"""

print('Starting by getting ceiling of number of steps and valid steps')
steps_per_epoch = int(np.ceil(train_generator.samples/train_generator.batch_size))
val_steps_per_epoch = int(np.ceil(valid_generator.samples/valid_generator.batch_size))
print(steps_per_epoch, val_steps_per_epoch)
print('Starting to train...')
hist = model.fit(
    train_generator,
    epochs=10,
    verbose=1,
    steps_per_epoch=steps_per_epoch,
    validation_data=valid_generator,
    validation_steps=val_steps_per_epoch).history
print('DONE!')

final_loss, final_accuracy = model.evaluate(valid_generator, steps=val_steps_per_epoch)
print(f"Final loss: {final_loss}")
print(f"Final accuracy: {final_accuracy*100}")

"""Exporting Model"""

EMOJI_MODEL = "saved_models/emojify"
tf.keras.experimental.export_saved_model(model, EMOJI_MODEL)

val_image_batch, val_label_batch = next(iter(valid_generator))
emoji_model = tf.keras.experimental.load_from_saved_model(EMOJI_MODEL, custom_objects={'KerasLayer':hub.KerasLayer})

val_image_batch, val_label_batch = next(iter(valid_generator))
true_label_ids = np.argmax(val_label_batch, axis=-1)


tf_model_predictions = emoji_model.predict(val_image_batch)
tf_pred_dataframe = pd.DataFrame(tf_model_predictions)
tf_pred_dataframe.columns = dataset_labels
print("Prediction results for the first elements")
tf_pred_dataframe.head()

predicted_ids = np.argmax(tf_model_predictions, axis=-1)
predicted_labels = dataset_labels[predicted_ids]
plt.figure(figsize=(10,9))
plt.subplots_adjust(hspace=0.5)
for n in range(20):
  plt.subplot(6,5,n+1)
  plt.imshow(val_image_batch[n])
  color = "green" if predicted_ids[n] == true_label_ids[n] else "red"
  plt.title(predicted_labels[n].title(), color=color)
  plt.axis('off')
_ = plt.suptitle("Model predictions (green: correct, red: incorrect)")

!mkdir "tflite_models"
TFLITE_MODEL = "tflite_models/emojify.tflite"
TFLITE_QUANT_MODEL = "tflite_models/emojify_quant.tflite"

# Get the concrete function from the Keras model.
run_model = tf.function(lambda x : emoji_model(x))
# Save the concrete function.
concrete_func = run_model.get_concrete_function(
tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype)
)
# Convert the model
converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])
converted_tflite_model = converter.convert()
open(TFLITE_MODEL, "wb").write(converted_tflite_model)
# Convert the model to quantized version with post-training quantization
converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])
converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]
tflite_quant_model = converter.convert()
open(TFLITE_QUANT_MODEL, "wb").write(tflite_quant_model)
print("TFLite models and their sizes:")
!ls "tflite_models" -lh